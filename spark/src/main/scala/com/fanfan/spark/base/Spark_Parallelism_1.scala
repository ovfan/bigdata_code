package com.fanfan.spark.base

import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

object Spark_Parallelism_1 {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("Test").setMaster("local[*]")
    // é…ç½®å¯¹è±¡ä¸­è®¾ç½®åˆ†åŒºæ•°é‡
    conf.set("spark.default.parallelism", "6")

    val sc = new SparkContext(conf)

    // ç£ç›˜æ–‡ä»¶--åˆ†åŒºæ•°é‡
    // minpartitions = 3
    val rdd1 = sc.textFile("spark/src/main/resources/num.txt", 3)

    // åˆ†åŒºæ•°é‡è®¡ç®—:
    // ç†æƒ³çŠ¶æ€ä¸‹: goalsize = 7 / 3 =2 ,æ¯ä¸ªåˆ†åŒºæ”¾å…¥ä¸¤ä¸ªå­—èŠ‚
    // totalsize / goalsize = 3....1  33% > 10% æ‰€ä»¥ä¼šå†åˆ›å»ºä¸€ä¸ªåˆ†åŒºï¼Œ3 + 1 =4

    // éªŒè¯ï¼š
    rdd1.saveAsTextFile("spark/src/main/resources/r3")
    //æœ€ç»ˆåˆ†åŒºæ•°é‡ä¸º: ğŸ‘‰ 4ä¸ª
    sc.stop()
  }
}
